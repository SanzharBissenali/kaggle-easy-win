{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkXHwdU-ylCi",
        "outputId": "92be2a89-8159-4e67-896b-d829d9992bb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Setup:\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle # Install the Kaggle library\n",
        "from google.colab import files\n",
        "files.upload() # A button will appear to browse and upload the kaggle.json file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "WJxqKjkL4oKa",
        "outputId": "db84697a-0699-478c-e8c1-cab50fbcf851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b434184f-aabb-4d93-8abf-ba73c41eb820\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b434184f-aabb-4d93-8abf-ba73c41eb820\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = pd.read_csv(\"/content/drive/My Drive/cs 155/Project_1/data/test.csv\")   ### Change the file path\n",
        "training_set = pd.read_csv(\"/content/drive/My Drive/cs 155/Project_1/data/train.csv\") ### Change the file path"
      ],
      "metadata": {
        "id": "gWbuMF9ZyurU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lb = LabelBinarizer()\n",
        "lb.fit(training_set[\"Popularity_Type\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "pnmh3r0t1pG9",
        "outputId": "ed3ed8cf-2b7d-460f-9b77-0878fd39f94c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelBinarizer()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelBinarizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LabelBinarizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.LabelBinarizer.html\">?<span>Documentation for LabelBinarizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LabelBinarizer()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "means = None\n",
        "stdevs = None\n",
        "\n",
        "# Define preprocessing transform\n",
        "def conversion_transform(df, lb=None, is_test = False):\n",
        "    # drop text columns\n",
        "    new_df = df.drop(columns=['track_href', 'uri', 'type', 'analysis_url'])\n",
        "\n",
        "    if is_test == True:\n",
        "        new_df = new_df.drop(columns=['ID'])\n",
        "\n",
        "    # Handle dates\n",
        "    date_column = new_df[\"track_album_release_date\"].astype(str)\n",
        "\n",
        "    parsed = pd.to_datetime(date_column, format='%Y-%m-%d', errors='coerce')\n",
        "    new_df[\"year\"] = parsed.dt.year\n",
        "    new_df[\"month\"] = parsed.dt.month\n",
        "    new_df[\"day\"] = parsed.dt.day\n",
        "\n",
        "    # For year-only dates, extract year and default month/day to 1\n",
        "    year_only_mask = new_df[\"year\"].isna()\n",
        "    new_df.loc[year_only_mask, \"year\"] = pd.to_numeric(date_column[year_only_mask], errors='coerce')\n",
        "    new_df.loc[year_only_mask, \"month\"] = 1\n",
        "    new_df.loc[year_only_mask, \"day\"] = 1\n",
        "\n",
        "    new_df = new_df.drop(columns='track_album_release_date')\n",
        "\n",
        "    if not is_test:\n",
        "        # Binarization of the output\n",
        "        column_names = list(new_df.columns.values)\n",
        "        column_names.append(column_names.pop(column_names.index('Popularity_Type')))\n",
        "        new_df = new_df[column_names]\n",
        "\n",
        "        # don't fit per fold\n",
        "        new_df[\"Popularity_Type\"] = lb.transform(new_df[\"Popularity_Type\"]).astype(int)\n",
        "\n",
        "    # replace all the nan values with zero\n",
        "    new_df = new_df.fillna(0)\n",
        "\n",
        "    return new_df\n",
        "\n",
        "def fit_normalizer(train_df_converted):\n",
        "  X = train_df_converted.iloc[:,:-1]\n",
        "  means = X.mean(axis=0)\n",
        "  stdevs = X.std(axis=0).replace(0,1) # avoid dividing by 0\n",
        "  feature_columns = train_df_converted.columns[:-1].tolist()\n",
        "  return means, stdevs, feature_columns\n",
        "\n",
        "def preprocessing_with_stats(df, lb, means, stdevs, feature_columns, is_test = False):\n",
        "    conv = conversion_transform(df, lb=lb, is_test=is_test)\n",
        "    if is_test:\n",
        "        X = conv[feature_columns]\n",
        "        X = (X-means)/stdevs\n",
        "        return X\n",
        "    else:\n",
        "        X = conv.iloc[:,:-1]\n",
        "        y=conv.iloc[:,-1]\n",
        "        X = (X-means)/stdevs\n",
        "        return pd.concat([X,y], axis=1)\n",
        "\n",
        "# Save IDs\n",
        "test_IDs = test_set['ID'].values"
      ],
      "metadata": {
        "id": "uB7lBn14y1ta"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Music Dataloader\n",
        "class MusicDataset(Dataset):\n",
        "    \"\"\"Music dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, dataset, is_test, transform=None):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            dataset: Pandas dataframe\n",
        "            transform: Transformation to data\n",
        "        \"\"\"\n",
        "\n",
        "        data = dataset\n",
        "        if transform:\n",
        "            data = transform(dataset, is_test)\n",
        "\n",
        "        # If it's the test set, there are no labels\n",
        "        if is_test:\n",
        "            self.X = torch.tensor( data.values, dtype=torch.float32)\n",
        "            self.y = None\n",
        "\n",
        "        else:\n",
        "        # example: last column is label, rest are features\n",
        "            self.X = torch.tensor(\n",
        "                data.iloc[:, :-1].values,\n",
        "                dtype=torch.float32\n",
        "            )\n",
        "            self.y = torch.tensor(\n",
        "                data.iloc[:, -1].values,\n",
        "                dtype=torch.long\n",
        "            )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "pPttt2a2zChM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Model ----------\n",
        "def build_model(num_features):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(num_features, 256),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(0.25),\n",
        "\n",
        "        nn.Linear(256, 128),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(0.25),\n",
        "\n",
        "        nn.Linear(128, 32),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(0.25),\n",
        "\n",
        "        nn.Linear(32, 1)   # logits\n",
        "    )\n",
        "\n",
        "# ---------- Metrics (convert logits -> probs via sigmoid) ----------\n",
        "def get_probs_from_logits(model, X):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(X).squeeze()\n",
        "        probs = torch.sigmoid(logits)  # convert to probabilities\n",
        "    model.train()\n",
        "    return probs\n",
        "\n",
        "def get_accuracy(model, dataset, threshold=0.5):\n",
        "    probs = get_probs_from_logits(model, dataset.X)\n",
        "    preds = (probs >= threshold).float()\n",
        "    y = dataset.y.float().squeeze()\n",
        "    return (preds == y).float().mean().item()\n",
        "\n",
        "def compute_auc(model, dataset):\n",
        "    probs = get_probs_from_logits(model, dataset.X).detach().cpu().numpy()\n",
        "    y_true = dataset.y.detach().cpu().numpy()\n",
        "    return roc_auc_score(y_true, probs)\n",
        "\n",
        "def best_threshold_and_acc(model, dataset):\n",
        "    probs = get_probs_from_logits(model, dataset.X).detach().cpu().numpy()\n",
        "    y = dataset.y.detach().cpu().numpy()\n",
        "\n",
        "    best_t, best_acc = 0.5, 0.0\n",
        "    for t in np.linspace(0.05, 0.95, 91):\n",
        "        preds = (probs >= t).astype(int)\n",
        "        acc = (preds == y).mean()\n",
        "        if acc > best_acc:\n",
        "            best_acc, best_t = acc, t\n",
        "    return best_t, best_acc\n",
        "\n",
        "# ---------- Training helper ----------\n",
        "def train_one_fold(model, train_loader, loss_fn, optimizer, scheduler=None, device=\"cpu\", epochs=70):\n",
        "    model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.float().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data).squeeze()\n",
        "            loss = loss_fn(logits, target)  # logits + BCEWithLogitsLoss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "# ---------- CV ----------\n",
        "device = \"cpu\"\n",
        "y_strat = training_set[\"Popularity_Type\"].values\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold_accs = []\n",
        "fold_aucs = []\n",
        "fold_tuned_accs = []\n",
        "fold_best_ts = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(training_set, y_strat), start=1):\n",
        "    train_df = training_set.iloc[train_idx].reset_index(drop=True)\n",
        "    val_df   = training_set.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    # Fold-specific stats (no leakage)\n",
        "    train_conv = conversion_transform(train_df, lb=lb, is_test=False)\n",
        "    means, stdevs, feature_cols = fit_normalizer(train_conv)\n",
        "\n",
        "    train_processed = preprocessing_with_stats(train_df, lb=lb, means=means, stdevs=stdevs,\n",
        "                                               feature_columns=feature_cols, is_test=False)\n",
        "    val_processed   = preprocessing_with_stats(val_df, lb=lb, means=means, stdevs=stdevs,\n",
        "                                               feature_columns=feature_cols, is_test=False)\n",
        "\n",
        "    train_ds = MusicDataset(train_processed, is_test=False, transform=None)\n",
        "    val_ds   = MusicDataset(val_processed,   is_test=False, transform=None)\n",
        "\n",
        "    # Move dataset tensors to device for faster eval\n",
        "    train_ds.X = train_ds.X.to(device)\n",
        "    train_ds.y = train_ds.y.to(device)\n",
        "    val_ds.X = val_ds.X.to(device)\n",
        "    val_ds.y = val_ds.y.to(device)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "\n",
        "    model = build_model(num_features=len(feature_cols))\n",
        "\n",
        "    # ---- Class imbalance handling via pos_weight ----\n",
        "    y_train = train_ds.y.float()\n",
        "    pos = y_train.sum()\n",
        "    neg = len(y_train) - pos\n",
        "    pos_weight = (neg / (pos + 1e-8)).detach().cpu()  # scalar tensor on CPU for loss init\n",
        "\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
        "\n",
        "    # ---- Optimizer + weight decay ----\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "    # ---- Scheduler helps often ----\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "\n",
        "    # Train\n",
        "    train_one_fold(model, train_loader, loss_fn, optimizer, scheduler=scheduler, device=device, epochs=70)\n",
        "\n",
        "    # Evaluate (after epoch 70)\n",
        "    val_acc = get_accuracy(model, val_ds, threshold=0.5)\n",
        "    val_auc = compute_auc(model, val_ds)\n",
        "    best_t, tuned_acc = best_threshold_and_acc(model, val_ds)\n",
        "\n",
        "    fold_accs.append(val_acc)\n",
        "    fold_aucs.append(val_auc)\n",
        "    fold_tuned_accs.append(tuned_acc)\n",
        "    fold_best_ts.append(best_t)\n",
        "\n",
        "    print(f\"Fold {fold}: acc@0.5={val_acc:.4f} | best_t={best_t:.2f} | tuned_acc={tuned_acc:.4f} | AUC={val_auc:.4f}\")\n",
        "\n",
        "print(\"\\nCV mean acc:\", float(np.mean(fold_accs)))\n",
        "print(\"CV std acc:\", float(np.std(fold_accs)))\n",
        "print(\"CV mean tuned acc:\", float(np.mean(fold_tuned_accs)))\n",
        "print(\"CV mean AUC:\", float(np.mean(fold_aucs)))\n",
        "print(\"CV std AUC:\", float(np.std(fold_aucs)))\n",
        "print(\"Mean best threshold:\", float(np.mean(fold_best_ts)))\n"
      ],
      "metadata": {
        "id": "5QBcefGpsiYj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "950989b5-6c54-4114-bd15-e2097f02fe43"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: acc@0.5=0.7206 | best_t=0.31 | tuned_acc=0.7516 | AUC=0.8175\n",
            "Fold 2: acc@0.5=0.6740 | best_t=0.35 | tuned_acc=0.7115 | AUC=0.7685\n",
            "Fold 3: acc@0.5=0.6831 | best_t=0.31 | tuned_acc=0.7426 | AUC=0.7835\n",
            "Fold 4: acc@0.5=0.6934 | best_t=0.34 | tuned_acc=0.7413 | AUC=0.7968\n",
            "Fold 5: acc@0.5=0.7073 | best_t=0.30 | tuned_acc=0.7448 | AUC=0.8024\n",
            "\n",
            "CV mean acc: 0.6956551671028137\n",
            "CV std acc: 0.01666245391822917\n",
            "CV mean tuned acc: 0.7383557098713712\n",
            "CV mean AUC: 0.793736081667791\n",
            "CV std AUC: 0.016703616589952095\n",
            "Mean best threshold: 0.32199999999999995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try changing the threshold to 0.32"
      ],
      "metadata": {
        "id": "U345d_gtFwc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Model ----------\n",
        "def build_model(num_features):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(num_features, 256),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(0.25),\n",
        "\n",
        "        nn.Linear(256, 128),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(0.25),\n",
        "\n",
        "        nn.Linear(128, 32),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(0.25),\n",
        "\n",
        "        nn.Linear(32, 1)   # logits\n",
        "    )\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def probs_from_logits(model, X):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(X).squeeze()\n",
        "        probs = torch.sigmoid(logits)\n",
        "    model.train()\n",
        "    return probs\n",
        "\n",
        "def get_accuracy(model, dataset, threshold=0.5):\n",
        "    probs = probs_from_logits(model, dataset.X)\n",
        "    preds = (probs >= threshold).float()\n",
        "    y = dataset.y.float().squeeze()\n",
        "    return (preds == y).float().mean().item()\n",
        "\n",
        "def compute_auc(model, dataset):\n",
        "    probs = probs_from_logits(model, dataset.X).detach().cpu().numpy()\n",
        "    y_true = dataset.y.detach().cpu().numpy()\n",
        "    return roc_auc_score(y_true, probs)\n",
        "\n",
        "def best_threshold_and_acc(model, dataset):\n",
        "    probs = probs_from_logits(model, dataset.X).detach().cpu().numpy()\n",
        "    y = dataset.y.detach().cpu().numpy()\n",
        "\n",
        "    best_t, best_acc = 0.5, 0.0\n",
        "    for t in np.linspace(0.05, 0.95, 91):\n",
        "        preds = (probs >= t).astype(int)\n",
        "        acc = (preds == y).mean()\n",
        "        if acc > best_acc:\n",
        "            best_acc, best_t = acc, t\n",
        "    return best_t, best_acc\n",
        "\n",
        "def train_one_fold(model, train_loader, loss_fn, optimizer, scheduler=None, device=\"cpu\", epochs=70):\n",
        "    model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.float().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data).squeeze()\n",
        "            loss = loss_fn(logits, target)  # logits + BCEWithLogitsLoss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "# ---------- CV ----------\n",
        "device = \"cpu\"\n",
        "y_strat = training_set[\"Popularity_Type\"].values\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# want one consistent threshold across folds, so use the mean we found:\n",
        "GLOBAL_THRESHOLD = 0.322\n",
        "\n",
        "fold_acc_05 = []\n",
        "fold_acc_global = []\n",
        "fold_acc_best = []\n",
        "fold_auc = []\n",
        "fold_best_t = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(training_set, y_strat), start=1):\n",
        "    train_df = training_set.iloc[train_idx].reset_index(drop=True)\n",
        "    val_df   = training_set.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    # Fold-specific stats (no leakage)\n",
        "    train_conv = conversion_transform(train_df, lb=lb, is_test=False)\n",
        "    means, stdevs, feature_cols = fit_normalizer(train_conv)\n",
        "\n",
        "    train_processed = preprocessing_with_stats(train_df, lb=lb, means=means, stdevs=stdevs,\n",
        "                                               feature_columns=feature_cols, is_test=False)\n",
        "    val_processed   = preprocessing_with_stats(val_df, lb=lb, means=means, stdevs=stdevs,\n",
        "                                               feature_columns=feature_cols, is_test=False)\n",
        "\n",
        "    train_ds = MusicDataset(train_processed, is_test=False, transform=None)\n",
        "    val_ds   = MusicDataset(val_processed,   is_test=False, transform=None)\n",
        "\n",
        "    # Move tensors to device\n",
        "    train_ds.X = train_ds.X.to(device); train_ds.y = train_ds.y.to(device)\n",
        "    val_ds.X   = val_ds.X.to(device);   val_ds.y   = val_ds.y.to(device)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "\n",
        "    model = build_model(num_features=len(feature_cols))\n",
        "\n",
        "    # Class imbalance handling\n",
        "    y_train = train_ds.y.float()\n",
        "    pos = y_train.sum()\n",
        "    neg = len(y_train) - pos\n",
        "    pos_weight = (neg / (pos + 1e-8)).detach().cpu()\n",
        "\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "\n",
        "    train_one_fold(model, train_loader, loss_fn, optimizer, scheduler=scheduler, device=device, epochs=70)\n",
        "\n",
        "    # Metrics\n",
        "    auc = compute_auc(model, val_ds)\n",
        "    acc05 = get_accuracy(model, val_ds, threshold=0.5)\n",
        "\n",
        "    best_t, acc_best = best_threshold_and_acc(model, val_ds)\n",
        "    acc_global = get_accuracy(model, val_ds, threshold=GLOBAL_THRESHOLD)\n",
        "\n",
        "    fold_auc.append(auc)\n",
        "    fold_acc_05.append(acc05)\n",
        "    fold_best_t.append(best_t)\n",
        "    fold_acc_best.append(acc_best)\n",
        "    fold_acc_global.append(acc_global)\n",
        "\n",
        "    print(\n",
        "        f\"Fold {fold}: \"\n",
        "        f\"acc@0.5={acc05:.4f} | \"\n",
        "        f\"acc@global({GLOBAL_THRESHOLD:.3f})={acc_global:.4f} | \"\n",
        "        f\"best_t={best_t:.2f} | acc@best_t={acc_best:.4f} | \"\n",
        "        f\"AUC={auc:.4f}\"\n",
        "    )\n",
        "\n",
        "print(\"\\nCV mean AUC:\", float(np.mean(fold_auc)))\n",
        "print(\"CV std AUC:\", float(np.std(fold_auc)))\n",
        "\n",
        "print(\"CV mean acc@0.5:\", float(np.mean(fold_acc_05)))\n",
        "print(\"CV mean acc@global:\", float(np.mean(fold_acc_global)))\n",
        "\n",
        "print(\"Mean best threshold:\", float(np.mean(fold_best_t)))\n",
        "print(\"CV mean acc@best_t:\", float(np.mean(fold_acc_best)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMKe0jh9Easo",
        "outputId": "1825b4e1-f223-4876-bf2e-95d27ea3d1f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: acc@0.5=0.7361 | acc@global(0.322)=0.7671 | best_t=0.33 | acc@best_t=0.7684 | AUC=0.8278\n",
            "Fold 2: acc@0.5=0.6818 | acc@global(0.322)=0.7206 | best_t=0.36 | acc@best_t=0.7296 | AUC=0.7762\n",
            "Fold 3: acc@0.5=0.6895 | acc@global(0.322)=0.7348 | best_t=0.29 | acc@best_t=0.7490 | AUC=0.7855\n",
            "Fold 4: acc@0.5=0.7025 | acc@global(0.322)=0.7245 | best_t=0.22 | acc@best_t=0.7309 | AUC=0.7909\n",
            "Fold 5: acc@0.5=0.7008 | acc@global(0.322)=0.7474 | best_t=0.33 | acc@best_t=0.7487 | AUC=0.8022\n",
            "\n",
            "CV mean AUC: 0.7965376415608115\n",
            "CV std AUC: 0.017742677766221654\n",
            "CV mean acc@0.5: 0.7021218061447143\n",
            "CV mean acc@global: 0.7388738393783569\n",
            "Mean best threshold: 0.30599999999999994\n",
            "CV mean acc@best_t: 0.74534248503576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "thresholds vary by fold (0.22 to 0.36), suggesting calibration instability. A simple fix is to choose threshold based on the training folds only (not the validation fold), which avoids peeking and produces a more stable threshold."
      ],
      "metadata": {
        "id": "2zrXDDoUHTfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(num_features):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(num_features, 256),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(0.25),\n",
        "        nn.Linear(256, 128),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(0.25),\n",
        "        nn.Linear(128, 32),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(0.25),\n",
        "        nn.Linear(32, 1)   # logits\n",
        "    )\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def probs_from_logits(model, X):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(X).squeeze()\n",
        "        probs = torch.sigmoid(logits)\n",
        "    model.train()\n",
        "    return probs\n",
        "\n",
        "def get_accuracy_from_probs(probs_np, y_np, threshold):\n",
        "    preds = (probs_np >= threshold).astype(int)\n",
        "    return (preds == y_np).mean()\n",
        "\n",
        "def best_threshold_from_oof_probs(oof_probs, oof_y, grid=None):\n",
        "    if grid is None:\n",
        "        grid = np.linspace(0.05, 0.95, 91)\n",
        "    best_t, best_acc = 0.5, 0.0\n",
        "    for t in grid:\n",
        "        acc = get_accuracy_from_probs(oof_probs, oof_y, t)\n",
        "        if acc > best_acc:\n",
        "            best_acc, best_t = acc, t\n",
        "    return best_t, best_acc\n",
        "\n",
        "def compute_auc(model, dataset):\n",
        "    probs = probs_from_logits(model, dataset.X).detach().cpu().numpy()\n",
        "    y_true = dataset.y.detach().cpu().numpy()\n",
        "    return roc_auc_score(y_true, probs)\n",
        "\n",
        "def train_epochs(model, train_loader, loss_fn, optimizer, scheduler=None, device=\"cpu\", epochs=70):\n",
        "    model.to(device)\n",
        "    for _ in range(epochs):\n",
        "        for Xb, yb in train_loader:\n",
        "            Xb = Xb.to(device)\n",
        "            yb = yb.float().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(Xb).squeeze()\n",
        "            loss = loss_fn(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "def make_fold_datasets(train_df, val_df, lb, means, stdevs, feature_cols, device):\n",
        "    train_processed = preprocessing_with_stats(\n",
        "        train_df, lb=lb, means=means, stdevs=stdevs,\n",
        "        feature_columns=feature_cols, is_test=False\n",
        "    )\n",
        "    val_processed = preprocessing_with_stats(\n",
        "        val_df, lb=lb, means=means, stdevs=stdevs,\n",
        "        feature_columns=feature_cols, is_test=False\n",
        "    )\n",
        "\n",
        "    train_ds = MusicDataset(train_processed, is_test=False, transform=None)\n",
        "    val_ds   = MusicDataset(val_processed,   is_test=False, transform=None)\n",
        "\n",
        "    # Move tensors onto device\n",
        "    train_ds.X = train_ds.X.to(device); train_ds.y = train_ds.y.to(device)\n",
        "    val_ds.X   = val_ds.X.to(device);   val_ds.y   = val_ds.y.to(device)\n",
        "    return train_ds, val_ds\n",
        "\n",
        "def make_loss_and_optim(model, y_train_tensor, device, lr=1e-3, weight_decay=1e-4):\n",
        "    # pos_weight for imbalance: (neg/pos)\n",
        "    y_train = y_train_tensor.float()\n",
        "    pos = y_train.sum()\n",
        "    neg = len(y_train) - pos\n",
        "    pos_weight = (neg / (pos + 1e-8)).detach().cpu()\n",
        "\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "    return loss_fn, optimizer, scheduler\n",
        "\n",
        "# ---------- NO-PEEK threshold selection on outer TRAIN only ----------\n",
        "def select_threshold_no_peek(train_df_outer, y_outer_raw, lb, device,\n",
        "                             inner_splits=4, epochs=70, batch_size=64, seed=123):\n",
        "    \"\"\"\n",
        "    Returns a threshold chosen using ONLY outer-training data.\n",
        "    Uses inner StratifiedKFold to create out-of-fold probabilities,\n",
        "    then chooses threshold maximizing OOF accuracy.\n",
        "    \"\"\"\n",
        "    inner_skf = StratifiedKFold(n_splits=inner_splits, shuffle=True, random_state=seed)\n",
        "\n",
        "    oof_probs = np.zeros(len(train_df_outer), dtype=np.float64)\n",
        "\n",
        "    # Inner splits are on outer training set\n",
        "    for inner_train_idx, inner_holdout_idx in inner_skf.split(train_df_outer, y_outer_raw):\n",
        "        inner_train_df = train_df_outer.iloc[inner_train_idx].reset_index(drop=True)\n",
        "        inner_hold_df  = train_df_outer.iloc[inner_holdout_idx].reset_index(drop=True)\n",
        "\n",
        "        # Fit fold-specific normalizer on INNER TRAIN ONLY\n",
        "        inner_train_conv = conversion_transform(inner_train_df, lb=lb, is_test=False)\n",
        "        means, stdevs, feature_cols = fit_normalizer(inner_train_conv)\n",
        "\n",
        "        inner_train_ds, inner_hold_ds = make_fold_datasets(\n",
        "            inner_train_df, inner_hold_df, lb, means, stdevs, feature_cols, device\n",
        "        )\n",
        "\n",
        "        inner_loader = DataLoader(inner_train_ds, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        model = build_model(num_features=len(feature_cols)).to(device)\n",
        "        loss_fn, optimizer, scheduler = make_loss_and_optim(model, inner_train_ds.y, device)\n",
        "\n",
        "        train_epochs(model, inner_loader, loss_fn, optimizer, scheduler=scheduler, device=device, epochs=epochs)\n",
        "\n",
        "        # Get probabilities for inner holdout; store into correct positions of oof_probs\n",
        "        probs_hold = probs_from_logits(model, inner_hold_ds.X).detach().cpu().numpy().reshape(-1)\n",
        "        # Map back to the correct indices in the outer train array:\n",
        "        oof_probs[inner_holdout_idx] = probs_hold\n",
        "\n",
        "    # Convert outer raw labels -> numeric 0/1 using lb\n",
        "    oof_y = lb.transform(train_df_outer[\"Popularity_Type\"]).astype(int).reshape(-1)\n",
        "\n",
        "    best_t, best_acc = best_threshold_from_oof_probs(oof_probs, oof_y)\n",
        "    return best_t, best_acc\n",
        "\n",
        "# ---------- Outer CV using no-peek threshold ----------\n",
        "device = \"cpu\"\n",
        "\n",
        "y_strat = training_set[\"Popularity_Type\"].values\n",
        "outer_skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "outer_acc_at_05 = []\n",
        "outer_acc_at_nop = []\n",
        "outer_auc = []\n",
        "outer_thresholds = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(outer_skf.split(training_set, y_strat), start=1):\n",
        "    train_df_outer = training_set.iloc[train_idx].reset_index(drop=True)\n",
        "    val_df_outer   = training_set.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    # 1) Choose threshold using ONLY outer training data (no-peek)\n",
        "    best_t_nop, oof_acc = select_threshold_no_peek(\n",
        "        train_df_outer,\n",
        "        y_outer_raw=train_df_outer[\"Popularity_Type\"].values,\n",
        "        lb=lb,\n",
        "        device=device,\n",
        "        inner_splits=4,\n",
        "        epochs=70,\n",
        "        batch_size=64,\n",
        "        seed=100 + fold\n",
        "    )\n",
        "    outer_thresholds.append(best_t_nop)\n",
        "\n",
        "    # 2) Train final model on FULL outer training fold\n",
        "    train_conv = conversion_transform(train_df_outer, lb=lb, is_test=False)\n",
        "    means, stdevs, feature_cols = fit_normalizer(train_conv)\n",
        "\n",
        "    train_ds, val_ds = make_fold_datasets(\n",
        "        train_df_outer, val_df_outer, lb, means, stdevs, feature_cols, device\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "\n",
        "    model = build_model(num_features=len(feature_cols)).to(device)\n",
        "    loss_fn, optimizer, scheduler = make_loss_and_optim(model, train_ds.y, device)\n",
        "\n",
        "    train_epochs(model, train_loader, loss_fn, optimizer, scheduler=scheduler, device=device, epochs=70)\n",
        "\n",
        "    # 3) Evaluate on outer val using threshold chosen without peeking\n",
        "    probs_val = probs_from_logits(model, val_ds.X).detach().cpu().numpy().reshape(-1)\n",
        "    y_val = val_ds.y.detach().cpu().numpy().reshape(-1)\n",
        "\n",
        "    acc05 = get_accuracy_from_probs(probs_val, y_val, 0.5)\n",
        "    acc_nop = get_accuracy_from_probs(probs_val, y_val, best_t_nop)\n",
        "    auc = roc_auc_score(y_val, probs_val)\n",
        "\n",
        "    outer_acc_at_05.append(acc05)\n",
        "    outer_acc_at_nop.append(acc_nop)\n",
        "    outer_auc.append(auc)\n",
        "\n",
        "    print(\n",
        "        f\"Fold {fold}: \"\n",
        "        f\"no-peek_t={best_t_nop:.2f} (OOF acc~{oof_acc:.4f}) | \"\n",
        "        f\"val acc@0.5={acc05:.4f} | val acc@no-peek={acc_nop:.4f} | \"\n",
        "        f\"val AUC={auc:.4f}\"\n",
        "    )\n",
        "\n",
        "print(\"\\nNo-peek threshold results\")\n",
        "print(\"Mean no-peek threshold:\", float(np.mean(outer_thresholds)))\n",
        "print(\"CV mean acc@0.5:\", float(np.mean(outer_acc_at_05)))\n",
        "print(\"CV mean acc@no-peek:\", float(np.mean(outer_acc_at_nop)))\n",
        "print(\"CV mean AUC:\", float(np.mean(outer_auc)))\n",
        "print(\"CV std AUC:\", float(np.std(outer_auc)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuKV-rQkGjue",
        "outputId": "c2a75fd7-53cb-480b-c173-be965ce8f7a4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: no-peek_t=0.32 (OOF acc~0.7299) | val acc@0.5=0.7296 | val acc@no-peek=0.7633 | val AUC=0.8260\n",
            "Fold 2: no-peek_t=0.30 (OOF acc~0.7379) | val acc@0.5=0.6688 | val acc@no-peek=0.7050 | val AUC=0.7622\n",
            "Fold 3: no-peek_t=0.29 (OOF acc~0.7273) | val acc@0.5=0.6882 | val acc@no-peek=0.7413 | val AUC=0.7862\n",
            "Fold 4: no-peek_t=0.32 (OOF acc~0.7496) | val acc@0.5=0.7050 | val acc@no-peek=0.7296 | val AUC=0.7937\n",
            "Fold 5: no-peek_t=0.33 (OOF acc~0.7377) | val acc@0.5=0.7047 | val acc@no-peek=0.7474 | val AUC=0.8023\n",
            "\n",
            "No-peek threshold results\n",
            "Mean no-peek threshold: 0.312\n",
            "CV mean acc@0.5: 0.6992767563292199\n",
            "CV mean acc@no-peek: 0.7373214513134346\n",
            "CV mean AUC: 0.7940838395923586\n",
            "CV std AUC: 0.020826642123863846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qm2a9KejH158"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}